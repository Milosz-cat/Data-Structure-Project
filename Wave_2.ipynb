{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c03fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import h5py\n",
    "import lmdb\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44552f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448000 files belonging to 2 classes.\n",
      "Found 112000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = r\"C:\\Users\\Miloszek\\Desktop\\wave\\train\"\n",
    "valid_path = r\"C:\\Users\\Miloszek\\Desktop\\wave\\valid\"\n",
    "\n",
    "# Set the image dimensions\n",
    "image_size = (67, 193)  # Adjust to your desired image size\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 32  # Adjust batch size as needed\n",
    "\n",
    "# Load the image dataset from the directory without splitting\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    image_size=image_size,\n",
    "    batch_size=448,\n",
    "    shuffle=True,\n",
    "    seed=27,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.0  # Set to 0.0 to avoid splitting the dataset\n",
    ")\n",
    "\n",
    "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valid_path,\n",
    "    image_size=image_size,\n",
    "    batch_size=112,\n",
    "    shuffle=True,\n",
    "    seed=27,\n",
    "    label_mode='binary',\n",
    "    validation_split=0.0  # Set to 0.0 to avoid splitting the dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea85d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#DYSK\n",
    "# Set the number of smaller datasets to create\n",
    "num_subsets = 10\n",
    "\n",
    "# Create directories to save the smaller datasets\n",
    "train_save_dir = r'C:\\Users\\Miloszek\\Desktop\\subsets\\train_subsets'\n",
    "valid_save_dir = r'C:\\Users\\Miloszek\\Desktop\\subsets\\valid_subsets'\n",
    "os.makedirs(train_save_dir, exist_ok=True)\n",
    "os.makedirs(valid_save_dir, exist_ok=True)\n",
    "\n",
    "# Split and save the train dataset\n",
    "\n",
    "for i, (images, labels) in enumerate(train_ds):\n",
    "    if i >= num_subsets:\n",
    "        break\n",
    "    \n",
    "    subset_save_path = os.path.join(train_save_dir, f\"train_subset_{i}\")\n",
    "    os.makedirs(subset_save_path, exist_ok=True)\n",
    "    \n",
    "    csv_save_path = os.path.join(subset_save_path, \"labels.csv\")\n",
    "    \n",
    "    with open(csv_save_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"filename\", \"label\"])\n",
    "        \n",
    "        for j, (image, label) in enumerate(zip(images, labels)):\n",
    "            if j >= 448:\n",
    "                break\n",
    "            \n",
    "            image_save_path = os.path.join(subset_save_path, f\"image_{j}.png\")\n",
    "            image = tf.keras.preprocessing.image.array_to_img(image)\n",
    "            image.save(image_save_path, format=\"png\")\n",
    "            writer.writerow([image_save_path, int(label)])\n",
    "            \n",
    "\n",
    "# Split and save the validation dataset\n",
    "for i, (images, labels) in enumerate(valid_ds):\n",
    "    if i >= num_subsets:\n",
    "        break\n",
    "    \n",
    "    subset_save_path = os.path.join(valid_save_dir, f\"valid_subset_{i}\")\n",
    "    os.makedirs(subset_save_path, exist_ok=True)\n",
    "    \n",
    "    csv_save_path = os.path.join(subset_save_path, \"labels.csv\")\n",
    "    \n",
    "    with open(csv_save_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"filename\", \"label\"])\n",
    "        \n",
    "        for j, (image, label) in enumerate(zip(images, labels)):\n",
    "            if j >= 112:\n",
    "                break\n",
    "            \n",
    "            image_save_path = os.path.join(subset_save_path, f\"image_{j}.png\")\n",
    "            image = tf.keras.preprocessing.image.array_to_img(image)\n",
    "            image.save(image_save_path, format=\"png\")\n",
    "            writer.writerow([image_save_path, int(label)])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HD5F\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "data_dir = r\"C:\\Users\\Miloszek\\Desktop\\wave\"\n",
    "\n",
    "def load_images_labels(data_dir, num_images_per_class):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    class_dirs = os.listdir(data_dir)\n",
    "\n",
    "    for class_dir in class_dirs:\n",
    "        class_dir_path = os.path.join(data_dir, class_dir)\n",
    "        \n",
    "        if os.path.isdir(class_dir_path):\n",
    "            image_files = os.listdir(class_dir_path)\n",
    "            #selected_files = np.random.choice(image_files, num_images_per_class, replace=False)\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(class_dir_path, image_file)\n",
    "\n",
    "                # read the image using OpenCV\n",
    "                image = cv2.imread(image_path)\n",
    "                \n",
    "                # append the image and the label to the lists\n",
    "                images.append(image)\n",
    "                labels.append(1 if class_dir == \"ones\" else 0)  # assuming the classes are encoded in the folder names\n",
    "\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "train_images, train_labels = load_images_labels(os.path.join(data_dir, 'train'),448000)\n",
    "valid_images, valid_labels = load_images_labels(os.path.join(data_dir, 'valid'),112000)\n",
    "\n",
    "# shuffle the datasets\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n",
    "valid_images, valid_labels = shuffle(valid_images, valid_labels, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cac1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFREC\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def create_tf_example(image, label):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(tf.io.encode_jpeg(image).numpy()),\n",
    "        'label': _int64_feature(label)\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def save_tfrecords(images, labels, filename):\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for i in range(len(images)):\n",
    "            tf_example = create_tf_example(images[i], labels[i])\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "            \n",
    "save_tfrecords(train_images, train_labels, r'C:\\Users\\Miloszek\\Desktop\\_tf\\train.tfrecords')\n",
    "save_tfrecords(valid_images, valid_labels, r'C:\\Users\\Miloszek\\Desktop\\_tf\\valid.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HD5F\n",
    "with h5py.File(r\"C:\\Users\\Miloszek\\Desktop\\hdf5\\train.h5\", 'w') as f:\n",
    "    f.create_dataset('images', data=train_images)\n",
    "    f.create_dataset('labels', data=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HD5F\n",
    "with h5py.File(r\"C:\\Users\\Miloszek\\Desktop\\hdf5\\valid.h5\", 'w') as f:\n",
    "    f.create_dataset('images', data=valid_images)\n",
    "    f.create_dataset('labels', data=valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b65901a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Initialize EfficientNetB0 model\n",
    "ef = efn.EfficientNetB0(input_shape=(67, 193, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# Add your own classification layers on top\n",
    "x = ef.output\n",
    "x = GlobalAveragePooling2D()(x)  # Global average pooling to reduce spatial dimensions\n",
    "x = Dense(128, activation='relu')(x)  # Add a fully connected layer with 128 units\n",
    "x = Dense(1, activation='sigmoid')(x)  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=ef.input, outputs=x)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7182bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "14/14 [==============================] - 100s 3s/step - loss: 0.7070 - accuracy: 0.5379 - val_loss: 0.6984 - val_accuracy: 0.5179\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.5254 - accuracy: 0.7522 - val_loss: 0.7349 - val_accuracy: 0.5357\n",
      "1.1902508735656738\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.6739 - accuracy: 0.5938 - val_loss: 0.7020 - val_accuracy: 0.5446\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.5140 - accuracy: 0.7478 - val_loss: 0.7391 - val_accuracy: 0.5893\n",
      "0.760113000869751\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6584 - accuracy: 0.6228 - val_loss: 0.6855 - val_accuracy: 0.4821\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.5104 - accuracy: 0.7790 - val_loss: 0.5641 - val_accuracy: 0.7411\n",
      "0.8656671047210693\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.6266 - accuracy: 0.6473 - val_loss: 0.5772 - val_accuracy: 0.6607\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.4567 - accuracy: 0.7857 - val_loss: 0.5615 - val_accuracy: 0.6875\n",
      "1.0046722888946533\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.5900 - accuracy: 0.6808 - val_loss: 0.6760 - val_accuracy: 0.5893\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4698 - accuracy: 0.7723 - val_loss: 0.7039 - val_accuracy: 0.6250\n",
      "0.9009842872619629\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.6548 - accuracy: 0.6562 - val_loss: 0.6921 - val_accuracy: 0.5893\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.4840 - accuracy: 0.7656 - val_loss: 1.0237 - val_accuracy: 0.6161\n",
      "0.9193522930145264\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6121 - accuracy: 0.6629 - val_loss: 0.8254 - val_accuracy: 0.5982\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.4781 - accuracy: 0.7522 - val_loss: 1.1035 - val_accuracy: 0.6339\n",
      "0.8690605163574219\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 57s 2s/step - loss: 0.5593 - accuracy: 0.6905 - val_loss: 0.6206 - val_accuracy: 0.6696\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.4210 - accuracy: 0.8071 - val_loss: 0.7303 - val_accuracy: 0.6786\n",
      "0.6774899959564209\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.5873 - accuracy: 0.7165 - val_loss: 0.5849 - val_accuracy: 0.6518\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "0.7997102737426758\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.6152 - accuracy: 0.6585 - val_loss: 2.1083 - val_accuracy: 0.4911\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.5107 - accuracy: 0.7188 - val_loss: 4.4247 - val_accuracy: 0.4643\n",
      "0.9243133068084717\n"
     ]
    }
   ],
   "source": [
    "#DYSK\n",
    "# Path to the directories containing the subsets\n",
    "train_save_dir = r'C:\\Users\\Miloszek\\Desktop\\subsets\\train_subsets'\n",
    "valid_save_dir = r'C:\\Users\\Miloszek\\Desktop\\subsets\\valid_subsets'\n",
    "# Train the model on the current subset with validation data\n",
    "    \n",
    "# Iterate over the directories containing the training subsets\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    subset_path = os.path.join(train_save_dir, f\"train_subset_{i}\")\n",
    "    \n",
    "    # Load the images and labels from the current subset\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open(os.path.join(subset_path, \"labels.csv\")) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            image_path, label = row\n",
    "            image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "            image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            images.append(image_array)\n",
    "            labels.append(int(label))\n",
    "    \n",
    "    # Convert the images and labels to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Load the validation subset\n",
    "    valid_subset_path = os.path.join(valid_save_dir, f\"valid_subset_{i}\")\n",
    "    \n",
    "    valid_images = []\n",
    "    valid_labels = []\n",
    "    with open(os.path.join(valid_subset_path, \"labels.csv\")) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            image_path, label = row\n",
    "            valid_image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "            valid_image_array = tf.keras.preprocessing.image.img_to_array(valid_image)\n",
    "            valid_images.append(valid_image_array)\n",
    "            valid_labels.append(int(label))\n",
    "    \n",
    "    # Preprocess the validation images and labels as necessary\n",
    "    \n",
    "    # Convert the validation images and labels to numpy arrays\n",
    "    valid_images = np.array(valid_images)\n",
    "    valid_labels = np.array(valid_labels)\n",
    "    end_time = time.time()\n",
    "\n",
    "    \n",
    "    model.fit(images, labels, batch_size=32, epochs=2, validation_data=(valid_images, valid_labels))\n",
    "    \n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49dbb6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3/3 [==============================] - 36s 4s/step - loss: 0.7420 - accuracy: 0.4494 - val_loss: 1.1201 - val_accuracy: 0.4545\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3618 - accuracy: 0.8764 - val_loss: 3.6455 - val_accuracy: 0.6364\n",
      "0.019224882125854492\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1326 - accuracy: 0.9663 - val_loss: 1.2721 - val_accuracy: 0.5909\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0913 - accuracy: 0.9663 - val_loss: 1.0020 - val_accuracy: 0.5909\n",
      "0.00800180435180664\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.5909\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0950 - accuracy: 0.9775 - val_loss: 1.1307 - val_accuracy: 0.5909\n",
      "0.008919000625610352\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0193 - accuracy: 0.9888 - val_loss: 1.4462 - val_accuracy: 0.5909\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1029 - accuracy: 0.9663 - val_loss: 1.7755 - val_accuracy: 0.5909\n",
      "0.009656429290771484\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1421 - accuracy: 0.9663 - val_loss: 1.6504 - val_accuracy: 0.5909\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0503 - accuracy: 0.9775 - val_loss: 1.3461 - val_accuracy: 0.5909\n",
      "0.009004592895507812\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0466 - accuracy: 0.9888 - val_loss: 1.2429 - val_accuracy: 0.5909\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1122 - accuracy: 0.9551 - val_loss: 1.4695 - val_accuracy: 0.5909\n",
      "0.0\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0415 - accuracy: 0.9663 - val_loss: 1.9075 - val_accuracy: 0.5909\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0375 - accuracy: 0.9888 - val_loss: 2.2271 - val_accuracy: 0.5909\n",
      "0.007869482040405273\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0487 - accuracy: 0.9888 - val_loss: 2.2987 - val_accuracy: 0.5909\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0210 - accuracy: 0.9888 - val_loss: 1.8900 - val_accuracy: 0.5909\n",
      "0.0\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1683 - accuracy: 0.9326 - val_loss: 1.1322 - val_accuracy: 0.5455\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2210 - accuracy: 0.9438 - val_loss: 0.8060 - val_accuracy: 0.4545\n",
      "0.006704092025756836\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0561 - accuracy: 0.9888 - val_loss: 0.7863 - val_accuracy: 0.4545\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.0443 - accuracy: 0.9888 - val_loss: 0.8590 - val_accuracy: 0.5455\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#HD5F\n",
    "def load_slices(h5_file, num_slices):\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        images = f['images']\n",
    "        labels = f['labels']\n",
    "\n",
    "        slice_size = len(labels) // num_slices\n",
    "\n",
    "        for i in range(num_slices):\n",
    "            start_index = i * slice_size\n",
    "            end_index = (i + 1) * slice_size if i != num_slices - 1 else None  # get all remaining samples in the last slice\n",
    "\n",
    "            yield np.array(images[start_index:end_index]), np.array(labels[start_index:end_index])\n",
    "\n",
    "# load each slice and fit it into the model\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    # load validation data slice\n",
    "    train_images_slice, train_labels_slice = next(load_slices(r\"C:\\Users\\Miloszek\\Desktop\\hdf5\\train.h5\", 100))\n",
    "    valid_images_slice, valid_labels_slice = next(load_slices(r\"C:\\Users\\Miloszek\\Desktop\\hdf5\\valid.h5\", 100))\n",
    "    end_time = time.time()\n",
    "    \n",
    "    model.fit(train_images_slice, train_labels_slice, batch_size=32, epochs=2, validation_data=(valid_images_slice, valid_labels_slice))\n",
    "   \n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8786266b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "14/14 [==============================] - 78s 2s/step - loss: 0.7331 - accuracy: 0.5290 - val_loss: 0.7698 - val_accuracy: 0.4643\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.5331 - accuracy: 0.7232 - val_loss: 0.6965 - val_accuracy: 0.5089\n",
      "0.6376180648803711\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.2777 - accuracy: 0.8705 - val_loss: 0.9732 - val_accuracy: 0.5357\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.2492 - accuracy: 0.9040 - val_loss: 0.7635 - val_accuracy: 0.5536\n",
      "0.21647381782531738\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.2019 - accuracy: 0.9152 - val_loss: 0.8597 - val_accuracy: 0.5089\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1253 - accuracy: 0.9509 - val_loss: 0.9908 - val_accuracy: 0.5982\n",
      "0.23324322700500488\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.0484 - accuracy: 0.9933 - val_loss: 0.9829 - val_accuracy: 0.5982\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1096 - accuracy: 0.9621 - val_loss: 1.2109 - val_accuracy: 0.5714\n",
      "0.2337944507598877\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.2890 - accuracy: 0.8951 - val_loss: 1.2155 - val_accuracy: 0.5893\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 26s 2s/step - loss: 0.1456 - accuracy: 0.9397 - val_loss: 1.3544 - val_accuracy: 0.6250\n",
      "0.23434114456176758\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 25s 2s/step - loss: 0.1048 - accuracy: 0.9576 - val_loss: 1.3955 - val_accuracy: 0.6161\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0414 - accuracy: 0.9888 - val_loss: 1.5996 - val_accuracy: 0.5893\n",
      "0.23444437980651855\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 1.4272 - val_accuracy: 0.6339\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0610 - accuracy: 0.9777 - val_loss: 3.5469 - val_accuracy: 0.6250\n",
      "0.2500753402709961\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0692 - accuracy: 0.9821 - val_loss: 6.1585 - val_accuracy: 0.5357\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0917 - accuracy: 0.9732 - val_loss: 2.1836 - val_accuracy: 0.5714\n",
      "0.3438544273376465\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0893 - accuracy: 0.9665 - val_loss: 3.4304 - val_accuracy: 0.5982\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 2.2058 - val_accuracy: 0.5982\n",
      "0.2969629764556885\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0376 - accuracy: 0.9911 - val_loss: 1.1612 - val_accuracy: 0.6161\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 27s 2s/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 1.2355 - val_accuracy: 0.5982\n",
      "0.31298303604125977\n"
     ]
    }
   ],
   "source": [
    "#TFREC\n",
    "def parse_tf_example(example_proto):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.io.decode_jpeg(example['image'])\n",
    "    label = example['label']\n",
    "    return image, label\n",
    "\n",
    "def load_tfrecord_dataset(file_path):\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    parsed_dataset = raw_dataset.map(parse_tf_example)\n",
    "    return parsed_dataset\n",
    "\n",
    "def load_slices(tfrecord_path, num_slices):\n",
    "    dataset = load_tfrecord_dataset(tfrecord_path)\n",
    "    \n",
    "    slice_images = []\n",
    "    slice_labels = []\n",
    "\n",
    "    for image, label in dataset:\n",
    "        slice_images.append(image)\n",
    "        slice_labels.append(label)\n",
    "\n",
    "        if len(slice_images) >= num_slices:\n",
    "            yield np.array(slice_images), np.array(slice_labels)\n",
    "            slice_images = []\n",
    "            slice_labels = []\n",
    "\n",
    "    if slice_images:\n",
    "        yield np.array(slice_images), np.array(slice_labels)\n",
    "        \n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "    train_images_slice, train_labels_slice = next(load_slices(r\"C:\\Users\\Miloszek\\Desktop\\_tf\\train.tfrecords\", 448))\n",
    "    valid_images_slice, valid_labels_slice = next(load_slices(r\"C:\\Users\\Miloszek\\Desktop\\_tf\\valid.tfrecords\", 112))\n",
    "    end_time = time.time()\n",
    "    \n",
    "    model.fit(train_images_slice, train_labels_slice, batch_size=32, epochs=2, validation_data=(valid_images_slice, valid_labels_slice))\n",
    "    \n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554429c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = Image.open('.png')\n",
    "\n",
    "# Preprocess the image\n",
    "#img_array = np.array(img)\n",
    "#img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Make a prediction with the model\n",
    "#print(model.predict(img_array))\n",
    "#prediction = np.argmax(model.predict(img_array))\n",
    "#print('Dusty' if prediction == 0 else 'Clean')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
